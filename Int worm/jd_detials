#多进程版京东抓取详情页/评论
import json
import re
import time
import pandas as pd
import requests
from lxml import etree
# from xlrd import sheet
from openpyxl import Workbook
import asyncio
from httpx import AsyncClient

wb = Workbook()
ws = wb.active
ws.append([
    '标题',
    '价格',
    '店铺',
    '商品ID',
    '备注',
    '详情页网址',
    '商品图片网址',
    '所有评论',
    '视频晒单',
    '好评',
    '中评',
    '差评',
    '追评',
    '好评率(%)',
])

headers = {
    # 'authority': 'item.jd.com',
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    'accept-language': 'zh-CN,zh;q=0.9',
    'cookie': '__jdu=16522482835401340221388; shshshfpa=76c25328-0cc5-ad08-acc1-cf2b162a0a61-1652248285; shshshfpb=mtdSJv___ru3iBB2r3XR1VA; qrsc=3; pinId=x75lWuiSpgVj0zC68MzCk7V9-x-f3wj7; __jdv=76161171|direct|-|none|-|1673591153320; areaId=12; rkv=1.0; ipLoc-djd=12-988-993-58088; pin=jd_40695e02c9f49; unick=jd_183256hzr; ceshi3.com=201; _tp=awBBMDETGlbi5IYojh4OKdV7sL7LjyuX5Q%2FfhbyGaHk%3D; _pst=jd_40695e02c9f49; TrackID=15200YZbJFQ2NqAPlmTKJwbw3xWMqnm7xiWnIqLsxEZaxmegeeK69-ctgP4-xi5WDcq3jIwWqvWDD50uvgHOr11gNpJ9bWZU1ocJ9Di2bKwr43GYLmNLvfYrQdpGU47dH; thor=6CE4A6B80C7882E3213DE3A0D63156A98E7B5C33DE19619491557C91EEDD578993DE69FE11D114B8D1B8910BCB9F0EB48D163DDD690BD633A39CA33A6AE97A57AD4D66FAE6A7495178B99D5846472D1F197C9B50821E9E33DB1D4CBFE18D13B9AF2127C423BA617C563509E67A1E134CE1AC3B1F5415F6CA9695EA2A34E8AA0D1BD40E28CC34CA6C2433C40D83A16B7D28BF00DAF4D953AE60266FA131A3BEF1; jsavif=1; __jda=76161171.16522482835401340221388.1652248284.1673836410.1673855556.62; __jdb=76161171.7.16522482835401340221388|62.1673855556; __jdc=76161171; shshshfp=2e9583f1d0b6c7a4b52623edc457fde3; shshshsID=1041948e5d3260d5db1a51c998258a73_5_1673855794044; 3AB9D23F7A4B3C9B=WIU2U435OV5RTO6JZY6R7QHUM4E5VZHLJ3JDIHJTCABS4HKSIPTPE3A6ALJVTRH4RHAAKZ53CN3Q24H7GXN3YUXRJM',
    'referer': 'https://list.jd.com/',
    'sec-ch-ua': '" Not A;Brand";v="99", "Chromium";v="101", "Google Chrome";v="101"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"macOS"',
    'sec-fetch-dest': 'document',
    'sec-fetch-mode': 'navigate',
    'sec-fetch-site': 'same-origin',
    'sec-fetch-user': '?1',
    'upgrade-insecure-requests': '1',
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36',
}


async def get_data(keyword, page):
    for page in range(1, 2):
        # list_url = f'https://search.jd.com/Search?keyword={keyword}&page={page}&enc=utf-8'
        list_url = f'https://search.jd.com/Search?keyword={keyword}&qrst=1&stock=1&ev=exbrand_%E9%BB%9B%E7%8F%82%EF%BC%88DECORTE%EF%BC%89%5E&pvid=4cc26ac36e034bada71e0d62b443b4a2&page={page}&psort=3&click=0'
        async with AsyncClient(verify=False, timeout=30) as client:
            resp = await client.get(list_url, headers=headers)
            # print(resp.text)
            # 创建etree对象
            tree = etree.HTML(resp.text)
            # titles= tree.xpath('//div[@id="J_searchWrap"]//div[@class="gl-i-wrap"]//div[@class="p-name p-name-type-2"]//em')
            # print(len(titles))
            # for title in titles:
            #     print(title.xpath('string(.)').strip())
            lis = tree.xpath('//*[@id="J_goodsList"]/ul/li')
            for index, li in enumerate(lis):
                title_r = li.xpath('.//div[@class="p-name p-name-type-2"]//em')
                # print(title.xpath('string(.)').strip())
                title = title_r[0].xpath('string(.)').strip()
                title = title.replace('\n', '')
                # print(title.replace('\n',''))
                price = li.xpath('.//div[@class="p-price"]//i/text()')[0].strip()  # 价格

                # print(price)
                data_sku = li.xpath('./@data-sku')[0].strip()  # 商品唯一id
                # print(data_sku)
                # comment = li.xpath('.//div[@class="p-commit"]//a')  # 评论数
                shop_name = li.xpath('.//div[@class="p-shop"]//a//text()')[0].strip()  # 商铺名字
                # print(shop_name)
                icons = li.xpath('.//div[@class="p-icons"]/i/text()')  # 备注
                # comment = comment[0] if comment != [] else ''
                icons_n = ''
                for x in icons:
                    icons_n = icons_n + x.replace('\n', '')
                    icons_n = icons_n + ';'
                # print(icons_n)
                # detail_url = li.xpath('.//div[@class="p-name p-name-type-2"]/a/@href')[0]  # 详情页网址
                detail_url = f'https://npcitem.jd.hk/{data_sku}.html'
                # print(re.findall(r'data-lazy-img="(.*?)"', resp.text)[1])
                image_url = 'https:' + re.findall(r'data-lazy-img="(.*?)"', resp.text)[index]  # 图片网址
                # print(detail_url)
                response = await client.get(f'https://npcitem.jd.hk/{data_sku}.html', headers=headers)
                # print(response.text)
                # 商品产地
                try:
                    origin = re.findall(r'产地：(.*?)<', response.text)[0]
                except:
                    origin = ''
                # print(detail_url)
                # with open("cookies.txt", "r") as f:
                #     headers['cookie'] = json.load(f)
                # comment_url = f'https://club.jd.com/comment/productCommentSummaries.action?referenceIds={data_sku}'
                # time.sleep(1)
                # comments = requests.get(comment_url, headers=headers).json()
                # # print(comments)
                # info = {}
                # commentscount = comments['CommentsCount'][0]
                # all_comments = commentscount['CommentCountStr']
                # videocount = commentscount['VideoCountStr']
                # poorcount = commentscount['PoorCountStr']
                # aftercount = commentscount['AfterCountStr']
                # goodcount = commentscount['GoodCountStr']
                # generalcount = commentscount['GeneralCountStr']
                # goodrate = commentscount['GoodRate'] * 100
                item = [title, price, shop_name, data_sku, icons_n, detail_url, image_url, origin]
                # item = [title, price, shop_name, data_sku, icons_n, detail_url, image_url, all_comments, videocount, goodcount,
                #         generalcount, poorcount, aftercount, goodrate]
                print(item)
                ws.append(
                    [title, price, shop_name, data_sku, icons_n, detail_url, image_url, origin])
                # ws.append(
                #     [title, price, shop_name, data_sku, icons_n, detail_url, image_url, all_comments, videocount, goodcount,
                #      generalcount, poorcount, aftercount, goodrate])
            wb.save(rf'C:\Users\qchd\Desktop\美妆\{keyword}.xlsx')


async def main():
    tasks = []
    df = pd.read_excel(r'C:\Users\qchd\Desktop\抖音品牌.xlsx')
    # g_ids = df['商品ID']
    keyword_list = df['品牌名']
    for index, key_word in enumerate(keyword_list):
        tasks.append(asyncio.create_task(get_data(key_word, index)))
    await asyncio.wait(tasks)


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except Exception as e:
        print(e)
